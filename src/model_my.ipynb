{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model_my.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zdCXptCce7gj","executionInfo":{"status":"ok","timestamp":1638118869872,"user_tz":-540,"elapsed":503,"user":{"displayName":"성균관대장지호","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06228757969293348129"}},"outputId":"b822c701-96fc-4ef2-d5da-a13efc2f364e"},"source":["! nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Nov 28 17:01:09 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"e6kK0360vDp7"},"source":["# MODEL\n"]},{"cell_type":"markdown","metadata":{"id":"FM0pZ40re5CO"},"source":["-   main.py – Program execution file\n","-   model.py – Model class file\n","-   option.py – Argument file\n","-   utils – Folder keeping other Python files\n"]},{"cell_type":"code","metadata":{"id":"CEcM33XyMcwh","outputId":"91aa7b1a-5e04-429b-faeb-40a026c52aaf"},"source":["import random\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","\n","SEED = 18\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)"],"execution_count":null,"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x14bf3642d50>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"omYKT4XCe5CS"},"source":["def make_conv(in_channels, out_channels, kernel_size, stride=1, padding=1):\n","    return nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n","        nn.BatchNorm2d(out_channels),\n","        nn.LeakyReLU()\n","    )\n","\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, channels):\n","        super(ResidualBlock, self).__init__()\n","        self.block = nn.Sequential(\n","            make_conv(channels, channels // 2, kernel_size=1, padding=0),\n","            make_conv(channels// 2, channels , kernel_size=3)\n","        )\n","    \n","    def forward(self, x):\n","        return x + self.block(x)\n","\n","\n","class Darknet53(nn.Module):\n","    def __init__(self):\n","        super(Darknet53, self).__init__()\n","        self.darknet53 = nn.Sequential(\n","            make_conv(3, 32, kernel_size=3),\n","            make_conv(32, 64, kernel_size=3, stride=2),\n","            ResidualBlock(channels=64),\n","            make_conv(64, 128, kernel_size=3, stride=2),\n","            ResidualBlock(channels=128),\n","            ResidualBlock(channels=128),\n","            make_conv(128, 256, kernel_size=3, stride=2),\n","            ResidualBlock(channels=256),\n","            ResidualBlock(channels=256),\n","            ResidualBlock(channels=256),\n","            ResidualBlock(channels=256),\n","            ResidualBlock(channels=256),\n","            ResidualBlock(channels=256),\n","            ResidualBlock(channels=256),\n","            ResidualBlock(channels=256),\n","            make_conv(256, 512, kernel_size=3, stride=2),\n","            ResidualBlock(channels=512),\n","            ResidualBlock(channels=512),\n","            ResidualBlock(channels=512),\n","            ResidualBlock(channels=512),\n","            ResidualBlock(channels=512),\n","            ResidualBlock(channels=512),\n","            ResidualBlock(channels=512),\n","            ResidualBlock(channels=512),\n","            make_conv(512, 1024, kernel_size=3, stride=2),\n","            ResidualBlock(channels=1024),\n","            ResidualBlock(channels=1024),\n","            ResidualBlock(channels=1024),\n","            ResidualBlock(channels=1024),\n","        )\n","    \n","    def forward(self, x):\n","        return self.darknet53(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"itSsxKgkM0EO","outputId":"c55aecb9-eae5-4c2b-d23b-81f4c282b3c9"},"source":["import utils.iou as iou\n","\n","class YOLODetection(nn.Module):\n","    def __init__(self, anchors, img_size, num_classes):\n","        super(YOLODetection, self).__init__()\n","        self.anchors = anchors\n","        self.num_anchors = len(anchors)\n","        self.img_size = img_size\n","        self.num_classes = num_classes\n","        self.mse_loss = nn.MSELoss()\n","        self.bce_loss = nn.BCELoss()\n","        self.threshold = 0.5\n","        self.obj_scale = 1\n","        self.no_obj_scale = 100\n","\n","    def forward(self, x, t):\n","        device = torch.device('cuda' if x.is_cuda else 'cpu')\n","        num_batches = x.size(0)\n","        grid_size = x.size(2)\n","        \n","        # x = [batch, num_anchors * (num_class + 5), grid, grid]\n","        #   --> [batch, num_anchors,  grid, grid, num_class + 5]\n","        \n","        pred = x.view(num_batches, self.num_anchors, self.num_classes + 5, grid_size, grid_size)\\\n","             .permute(0, 1, 3, 4, 2).contiguous()\n","        \n","        # predicted values\n","        pred_cx = torch.sigmoid(pred[..., 0])\n","        pred_cy = torch.sigmoid(pred[..., 1])\n","        pred_w = pred[..., 2]\n","        pred_h = pred[..., 3]\n","        pred_conf = torch.sigmoid(pred[..., 4])\n","        pred_class = torch.sigmoid(pred[..., 5:])\n","        \n","        # offsef of grid\n","        stride = self.img_size / grid_size\n","        grid_x = torch.arange(grid_size, dtype=torch.float, device=device)\\\n","                      .repeat(grid_size, 1).view(1, 1, grid_size, grid_size)\n","        grid_y = torch.arange(grid_size, dtype=torch.float, device=device)\\\n","                      .repeat(grid_size, 1).t().view(1, 1, grid_size, grid_size)\n","        scaled_anchors = torch.as_tensor([(a_w / stride, a_h / stride) for a_w, a_h in self.anchors],\n","                                         dtype=torch.float, device=device)\n","        anchor_w = scaled_anchors[:, 0].view(1, self.num_anchors, 1, 1)\n","        anchor_h = scaled_anchors[:, 1].view(1, self.num_anchors, 1, 1)\n","        \n","        # calculate output\n","        pred_box = torch.zeros_like(pred[..., :4], device=device)\n","        pred_box[..., 0] = pred_cx + grid_x\n","        pred_box[..., 1] = pred_cy + grid_y\n","        pred_box[..., 2] = torch.exp(pred_w) * anchor_w\n","        pred_box[..., 3] = torch.exp(pred_h) * anchor_h\n","        \n","        output = (pred_box.view(num_batches, -1, 4) * stride,\n","                  pred_conf.view(num_batches, -1, 1),\n","                  pred_class.view(num_batches, -1, self.num_classes))\n","        output = torch.cat(output, -1)\n","        \n","        # test phase -> return output\n","        if t is None:\n","            return output, 0\n","        \n","        \n","        ############################################################################\n","        #여기서부터 모르겟아\n","        # train phase -> get loss\n","        obj_mask = torch.zeros(num_batches, self.num_anchors, grid_size, grid_size, dtype=torch.bool, device=device)\n","        no_obj_mask = torch.ones(num_batches, self.num_anchors, grid_size, grid_size, dtype=torch.bool, device=device)\n","        class_mask = torch.zeros(num_batches, self.num_anchors, grid_size, grid_size, dtype=torch.float, device=device)\n","        iou_scores = torch.zeros(num_batches, self.num_anchors, grid_size, grid_size, dtype=torch.float, device=device)\n","        t_cx = torch.zeros(num_batches, self.num_anchors, grid_size, grid_size, dtype=torch.float, device=device)\n","        t_cy = torch.zeros(num_batches, self.num_anchors, grid_size, grid_size, dtype=torch.float, device=device)\n","        t_w = torch.zeros(num_batches, self.num_anchors, grid_size, grid_size, dtype=torch.float, device=device)\n","        t_h = torch.zeros(num_batches, self.num_anchors, grid_size, grid_size, dtype=torch.float, device=device)\n","        t_class = torch.zeros(num_batches, self.num_anchors, grid_size, grid_size, self.num_classes, dtype=torch.float, device=device)\n","        \n","        \n","        # target boxes -> 0xywh\n","        t_boxes = t[:, 2:6] * grid_size\n","        gxy = t[:, 1:3]\n","        gwh = t[:, 3:5]\n","        \n","        # get best anchor\n","        ious = torch.stack([iou.box_wh_iou(anchor, gwh) for anchor in self.anchors])\n","        _, best_iou_idx = ious.max(0)\n","        \n","        b, target_labels = t[:, :2].long().t()\n","        gx, gy = gxy.t()\n","        gw, gh = gwh.t()\n","        gi, gj = gxy.long().t()\n","        \n","        obj_mask[b, best_iou_idx, gj, gi] = 1\n","        no_obj_mask[b, best_iou_idx, gj, gi] = 0\n","        \n","        # Set noobj mask to zero where iou exceeds ignore threshold\n","        for i, anchor_ious in enumerate(ious.t()):\n","            no_obj_mask[b[i], anchor_ious > self.threshold, gj[i], gi[i]] = 0\n","\n","        # Coordinates\n","        t_cx[b, best_iou_idx, gj, gi] = gx - gx.floor()\n","        t_cy[b, best_iou_idx, gj, gi] = gy - gy.floor()\n","\n","        # Width and height\n","        t_w[b, best_iou_idx, gj, gi] = torch.log(gw / self.anchors[best_iou_idx][:, 0] + 1e-16)\n","        t_h[b, best_iou_idx, gj, gi] = torch.log(gh / self.anchors[best_iou_idx][:, 1] + 1e-16)\n","\n","        # One-hot encoding of label\n","        t_class[b, best_iou_idx, gj, gi, target_labels] = 1\n","\n","        # Compute label correctness and iou at best anchor\n","        class_mask[b, best_iou_idx, gj, gi] = (pred_class[b, best_iou_idx, gj, gi].argmax(-1) == target_labels).float()\n","        iou_scores[b, best_iou_idx, gj, gi] = iou.box_iou(pred_box[b, best_iou_idx, gj, gi], t_boxes, x1y1x2y2=False)\n","\n","        t_conf = obj_mask.float()\n","        \n","        for i, anchor_ious in enumerate(ious.t()):\n","            no_obj_mask[b[i], anchor_ious > self.threshold, gj[i], gi[i]] = 0\n","        \n","        loss_x = self.mse_loss(pred_cx[obj_mask], t_cx[obj_mask])\n","        loss_y = self.mse_loss(pred_cy[obj_mask], t_cy[obj_mask])\n","        loss_w = self.mse_loss(pred_w[obj_mask], t_w[obj_mask])\n","        loss_h = self.mse_loss(pred_h[obj_mask], t_h[obj_mask])\n","        loss_box = loss_x + loss_y + loss_w + loss_h\n","        \n","        loss_conf_obj = self.bce_loss(pred_conf[obj_mask], t_conf[obj_mask])\n","        loss_conf_no_obj = self.bce_loss(pred_conf[no_obj_mask], t_conf[no_obj_mask])\n","        loss_conf = self.obj_scale * loss_conf_obj + self.no_obj_scale * loss_conf_no_obj\n","        \n","        loss_class = self.bce_loss(pred_class[obj_mask], t_class[obj_mask])\n","        \n","        loss = loss_box + loss_conf + loss_class\n","        return x, loss\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","test = torch.rand([2, 210, 13, 13], device=device)\n","a = YOLODetection(torch.tensor([[142,211], [212,2]], device=device), 416, 100).to(device)\n","ttt = torch.tensor([[0, 1, 0.4, 0.1, 0.1, 0.1],\n","                    [0, 2, 0.3, 0.2, 0.4, 0.5]], device=device)\n","c = a(test, ttt)\n","print(c[0].shape)\n","print(c[1])"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n","tensor([1., 2.], device='cuda:0')\n","torch.Size([2, 210, 13, 13])\n","tensor(166.6534, device='cuda:0')\n"]}]},{"cell_type":"code","metadata":{"id":"ewCzRjG-e5Cd"},"source":["class YOLOv3(nn.Module):\n","    def __init__(self, anchors, img_size=416, num_classes=1 + 67):\n","        super(YOLOv3, self).__init__()\n","        self.anchors = anchors\n","        \n","        last_out_channels = len(anchors) * (4 + 1 + num_classes)\n","        \n","        self.darknet53 = Darknet53()\n","        self.detection_block = self.make_detection_block(1024, 512, last_out_channels)\n","        self.yolo_layer = YOLODetection(anchors, img_size, num_classes)\n","    \n","    def forward(self, x, y=None):\n","        x = self.darknet53(x)\n","        x = self.detection_block(x)\n","        x_yolo, loss = self.yolo_layer(x, y)\n","        \n","        return x_yolo, loss\n","    \n","    def make_conv(self, in_channels, out_channels, kernel_size, stride=1, padding=1):       \n","        return nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n","            nn.BatchNorm2d(out_channels, eps=1e-5, momentum=0.9),\n","            nn.LeakyReLU(negative_slope=0.1))\n","    \n","    def make_detection_block(self, in_channels, out_channels, last_out_channels):\n","        return nn.Sequential(\n","            self.make_conv(in_channels, out_channels, kernel_size=1, padding=0),\n","            self.make_conv(out_channels, out_channels * 2, kernel_size=3),\n","            self.make_conv(out_channels * 2, out_channels, kernel_size=1, padding=0),\n","            self.make_conv(out_channels, out_channels * 2, kernel_size=3),\n","            self.make_conv(out_channels * 2, out_channels, kernel_size=1, padding=0),\n","            self.make_conv(out_channels, out_channels * 2, kernel_size=3),\n","            nn.Conv2d(out_channels * 2, last_out_channels, kernel_size=1, stride=1, padding=0, bias=True)\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M_ydD77oe5Ce","outputId":"f92f00a2-1607-406e-c0a6-c27c16842966"},"source":["anchors = [1, 2]\n","model = YOLOv3(anchors, 416, 100)\n","test = torch.rand([1, 3, 416, 416])\n","\n","y = model(test)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 210, 13, 13])\n"]}]}]}